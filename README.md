# Документация для инференса модели предсказания класса изображения

## Описание
Этот скрипт предназначен для загрузки предварительно обученной модели ResNet-101 и использования её для классификации изображений. Модель была дообучена на наборе данных, предоставленных организаторами НТО, который содержит изображения различных категорий.

## Использование
1. Подготовьте изображение, которое вы хотите классифицировать. Укажите путь к этому изображению в переменной `image_path`.
2. Запустите скрипт. Он загрузит изображение, выполнит преобразования и передаст его через модель для получения предсказаний.
3. После выполнения скрипта вы получите топ-5 предсказаний модели с указанием классов и соответствующих вероятностей.

## Зависимости
•	PyTorch (torch)
•	torchvision.transforms
•	joblib
•	PIL (Pillow)
•	matplotlib.pyplot

## Подробное описание
### Загрузка и обработка изображения
•	Импортируются необходимые библиотеки: `torch`, `torchvision.transforms`, `joblib`, `PIL.Image`.
•	Указывается путь к тестируемому изображению (`image_path`).
•	Изображение загружается с помощью библиотеки PIL (`PIL.Image.open`).

### Преобразование изображения
•	Создается объект `test_transform` с использованием `torchvision.transforms.Compose`, который выполняет следующие преобразования:
  1. Изменение размера изображения до 224x224 пикселей.
  2. Вырезание центральной части изображения размером 224x224.
  3. Преобразование изображения в тензор.
  4. Нормализация значений тензора по среднему и стандартному отклонению.

### Передача изображения через модель
•	 Устанавливается устройство (GPU, если доступен, иначе CPU).
•	 Изображение переносится на указанное устройство.
•	 Загружается предварительно обученная модель ResNet-101.
•	 Переопределяется последний полносвязный слой модели для соответствия количеству классов.
•	 Загружаются веса модели из файла.
•	 Модель перемещается на указанное устройство.

### Получение предсказаний
•	 Загружается объект `label_encoder` с помощью библиотеки `joblib`.
•	 Модель переводится в режим оценки.
•	 С выключенным вычислением градиентов:
•	 Выполняется прямой проход изображения через модель.
•	 Получаются топ-5 предсказанных классов.
•	 Индексы предсказанных классов переводятся в массив numpy.
•	 Вычисляются вероятности для каждого предсказанного класса.

### Вывод результатов
•	 Индексы классов преобразуются обратно в метки классов.
•	 Выводятся результаты предсказаний в формате "Топ-N предсказание: <метка класса>, Вероятность: <вероятность>".
•	 Строится столбчатая диаграмма, отображающая вероятности для каждого класса.

### Примечания
•	 Вероятности классов представлены в виде диаграммы для удобства визуализации.
•	 Модель и предобработка данных предполагают, что изображения имеют размер 224x224 пикселей. При необходимости, внесите соответствующие изменения.
•	 Убедитесь, что пути к файлам модели и кодировщика меток корректны.
•	 Для успешной работы скрипта требуется наличие файлов с весами модели и кодировщиком меток, соответственно `resnet_101.pth` и `label_encoder.pkl`.
 
# Документация для построения модели определения категории достопримечательности

## Описание
Этот скрипт предназначен для использования модели определения достопримечательностей с использованием библиотеки Transformers от Hugging Face. Он использует модель zero-shot-image-classification для классификации изображений, определяя, к каким категориям (таким как достопримечательности) они относятся, даже если эти категории не были использованы при обучении модели.

## Использование
1.	Загрузите необходимые изображения, которые вы хотите классифицировать, и определите кандидатские метки (текстовые описания категорий).
2.	Запустите скрипт и укажите пути к изображениям и список кандидатских меток.
3.	После выполнения скрипта вы получите топ-5 предсказанных категорий с соответствующими вероятностями.

## Зависимости
•	Matplotlib
•	Transformers

## Подробное описание

### Загрузка и инициализация модели
•	Импортируются необходимые библиотеки.
•	Инициализируется модель `image_classifier` с помощью метода `pipeline`, указывая задачу `zero-shot-image-classification` и модель `google/siglip-base-patch16-256-i18n`.

### Классификация изображений
•	Вызывается метод `image_classifier` для классификации изображения по отношению к кандидатским меткам `texts`.
•	Полученные выходные данные представлены в формате словаря, где каждый элемент содержит вероятность и соответствующую метку.
•	Результаты округляются до четырех знаков после запятой.
•	Выводится отсортированный список `outputs` по убыванию вероятности.

### Получение топ-5 предсказаний
•	Берутся первые пять элементов из отсортированного списка `outputs`.
•	Печатаются топ-5 предсказанных категорий с соответствующими вероятностями.

### Построение гистограммы
•	Создаются списки вероятностей `probabilities` и меток `labels` из топ-5 предсказаний.
•	Строится гистограмма с использованием `plt.bar`, где по оси X отображаются метки, а по оси Y – вероятности.

### Примечания
•	Для успешной работы скрипта требуется наличие библиотек Matplotlib и Transformers, а также соответствующей предварительно обученной модели.
•	Убедитесь, что переменные `images` и `texts` содержат корректные данные для классификации.

# Документация для создания модели классификации

## Описание
Этот скрипт предназначен для создания, трансферного обучения и сохранения модели классификации изображений с использованием архитектуры ResNet-101.

## Зависимости
•	PyTorch
•	Matplotlib

## Подробное описание

### Создание и инициализация модели
•	Импортируются необходимые библиотеки, включая PyTorch и Transformers.
•	Инициализируется предварительно обученная модель ResNet-101.

### Загрузка и подготовка данных
•	Импортируются необходимые библиотеки для работы с данными.
•	Определяется пользовательский класс `CustomDataset` для загрузки данных.
•	Определяются преобразования для обучающего и валидационного наборов данных.

### Создание DataLoader
•	Инициализируются загрузчики данных (`DataLoader`) для обучающего и валидационного наборов данных.

### Обучение модели
•	Определяется функция `train_model`, отвечающая за обучение модели.
•	Задаются гиперпараметры обучения: количество эпох, функция потерь, оптимизатор.
•	Модель обучается на обучающем наборе данных, оценивается на валидационном наборе.
•	Во время обучения отображаются потери и точность на обучающем и валидационном наборах данных.

### Визуализация процесса обучения
•	С помощью функции `plot_losses_and_accuracy` строятся графики изменения потерь и точности на обучающем и валидационном наборах данных.

### Сохранение модели
•	Обученная модель сохраняется в файл с помощью `torch.save()`.

### Выбор топ-5 подходящих мест
•	Вероятности классов для каждого изображения вычисляются с использованием модели.
•	Для каждого изображения отфильтровываются классы с ненулевой вероятностью.
•	Строится гистограмма вероятностей для топ-5 классов с наибольшими вероятностями.

### Примечания
•	Убедитесь, что все необходимые зависимости установлены перед запуском скрипта.
•	Проверьте правильность путей для сохранения модели и других результатов.
 
# Документация для обработки и анализа данных о достопримечательностях различных городов

## Описание
Данный скрипт предназначен для загрузки, обработки и анализа данных о достопримечательностях из нескольких городов. Данные включают в себя информацию о фотографиях достопримечательностей, их категориях и расположении.

## Зависимости
•	pandas
•	seaborn
•	matplotlib

## Подробное описание

### Загрузка и обработка данных
•	Импортируются необходимые библиотеки, включая pandas, seaborn и matplotlib.
•	Загружаются данные для каждого города (Екатеринбург, Нижний Новгород, Владимир, Ярославль) из файлов CSV.
•	Проводится анализ загруженных данных, включая проверку уникальных значений и наличие дубликатов.

### Визуализация данных
•	Строятся гистограммы для каждого города, отображающие количество достопримечательностей в каждой категории.
•	Для определенных объектов, имеющих несколько записей с разными названиями городов, отображаются изображения, чтобы проверить их сходство.
# Документация для поиска места по описанию

## Примечания
•	Убедитесь, что все необходимые зависимости установлены перед запуском скрипта.
•	Проверьте правильность путей к данным перед их загрузкой.
•	Предварительно ознакомьтесь с данными и их структурой для корректного анализа.

## Описание: 
В данном коде происходит использование языковой цепи для автоматического отвечания на вопросы, основываясь на контексте из предоставленных данных.

## Использование
Код загружает данные из файла CSV, переименовывает столбцы, создает шаблон для промпта, инициализирует языковую цепь, загружает документы и создает хранилище для них. Затем происходит тестирование ретривера и получение ответа на вопрос с использованием модели.

## Зависимости: 
В коде используются различные библиотеки и модули, такие как pandas, langchain и Hugging Face.

## Подробное описание: 
1. Данные загружаются из файла 'data.csv' и преобразуются в формат pandas DataFrame.
2. Столбцы 'Name' и 'en_txt' переименовываются в 'answer' и 'question'.
3. Создается шаблон для промпта, который будет использоваться для генерации ответов.
4. Инициализируется языковая цепь с использованием модели T5 из Hugging Face Hub.
5. Загруженные данные подготавливаются для использования в цепи.
6. Создается векторайзер с помощью Hugging Face Embeddings.
7. Документы разбиваются на части с помощью текстового сплиттера.
8. Создается и инициализируется хранилище FAISS для документов.
9. Тестируется ретривер и получается ближайший документ для заданного запроса.
10. Запускается языковая цепь для получения ответа на вопрос на основе найденного документа.

## Загрузка и инициализация модели: 
Используется модель T5 из Hugging Face Hub с параметрами temperature=0 и max_length=128.

## Получение предсказаний: 
Предсказания получаются путем использования языковой цепи для генерации ответов на вопросы с использованием контекста из предоставленных данных.

## Примечания: 
Код включает в себя процессы обработки данных, инициализации моделей и хранилища, тестирования ретривера и генерации ответов на вопросы.

## Инференс
```python

import base64
from PIL import Image
from io import BytesIO
from langchain.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain import HuggingFaceHub
model = 'tomaarsen/mpnet-base-nli-matryoshka'

embeddings = HuggingFaceEmbeddings(model_name=model)
db = FAISS.load_local("./Inference_models/faiss", embeddings, allow_dangerous_deserialization=True)
YOUR_API_KEY = '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'
# создаем шаблон для промта
prompt_template = """Используй контекст для ответа на вопрос, пользуясь следующими правилами:

Не изменяй текст, который находится в кавычках.
В конце обязательно добавь ссылку на полный документ
{answer}
img: {image}
"""
PROMPT = PromptTemplate(template=prompt_template, input_variables=['answer', 'image'])
chain = LLMChain(prompt=PROMPT, llm=HuggingFaceHub(
                                    repo_id='IlyaGusev/fred_t5_ru_turbo_alpaca',
                                    huggingfacehub_api_token=YOUR_API_KEY,
                                    model_kwargs={'temperature':0, 'max_length':128})
)

txt = input()
if len(txt):
    relevants = db.similarity_search(txt)
    doc = relevants[0].dict()['metadata']
    t = chain.run(doc)

```

# Документация по сервису

Клонируйте репозиторий
```bash
git clone https://gitlab.com/coffeface/nto_olimp.git
```
Запросите файлы модели у автора репозитория `kotyga.m.m@gmail.com`
Соберите образ Docker:
```bash
docker build -t Главная .
```
```bash
docker run -p 8501:8501 Главная
```
После этого приложение Streamlit будет доступно по адресу http://localhost:8501.